{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d60339-1ea7-4afb-8d00-a56ed457fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Setup plotting params.\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "sns.set_theme()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8865b0-1bb4-4eb5-8679-d69097a3c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants.\n",
    "DATA_PATH  = \"../data/\"\n",
    "ASTN_FILE = DATA_PATH + \"table1.csv\"\n",
    "SPECTRA_PATH = \"../data/spectra/\"\n",
    "COL_NAMES = [\"wavelength\", \"flux\", \"flux_err\"]\n",
    "\n",
    "# File list.\n",
    "data_astn = pd.read_csv(ASTN_FILE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d9565-a7c8-4c6e-bebd-29e1b65a1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ranges of each wing. The ranges are arbitrarily defined as\n",
    "#     [\n",
    "#         [flux_min - WING_P1, flux_min - WING_P2],\n",
    "#         [flux_min + WING_P2, flux_min + WING_P1]\n",
    "#     ]\n",
    "def get_wings(df, WING_P1 = 10, WING_P2 = 4):\n",
    "    # Get wavelength with minimum flux.\n",
    "    # NOTE. This could be improved with a Gaussian or Laplacian fit.\n",
    "    flux_min = df[\"wavelength\"][df[\"flux\"].idxmin()]\n",
    "\n",
    "    # Return wing ranges based on function parameters.\n",
    "    return (\n",
    "        (flux_min-WING_P1, flux_min-WING_P2),\n",
    "        (flux_min+WING_P2, flux_min+WING_P1)\n",
    "    )\n",
    "\n",
    "# Normalize set x, return x_scaled and x's minima and maxima.\n",
    "def scale(x):\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    return ((x - x_min)/(x_max - x_min), x_min, x_max)\n",
    "\n",
    "# De-scale x_scaled using previously obtained minima and maxima.\n",
    "def descale(x_scaled, x_min, x_max):\n",
    "    return (x_max - x_min) * x_scaled + x_min\n",
    "\n",
    "# Get and store the target temperature and fluxes for all spectra inside the li-\n",
    "#     mits defined by WING_P1 and WING_P2. The way these parameters are used is\n",
    "#     described in the `get_wings(...)` function.\n",
    "def get_row(in_row, WING_P1 = 10, WING_P2 = 4):\n",
    "    # Open dataframe.\n",
    "    df = pd.read_csv(\n",
    "        SPECTRA_PATH + in_row[\"filename\"],\n",
    "        sep=\"\\s+\", header=None, names=COL_NAMES\n",
    "    )\n",
    "\n",
    "    # Get wings and cut data outside of them. This leaves 190 rows per file.\n",
    "    w_lims = get_wings(df, WING_P1, WING_P2)\n",
    "    df.drop(df[(\n",
    "        ((w_lims[0][0]>df[\"wavelength\"]) | (df[\"wavelength\"]>w_lims[0][1])) &\n",
    "        ((w_lims[1][0]>df[\"wavelength\"]) | (df[\"wavelength\"]>w_lims[1][1]))\n",
    "    )].index, inplace=True)\n",
    "\n",
    "    # TODO. Scale importance of each parameter based on its error. We should\n",
    "    #       prioritize entires with a lower flux_err. Then, include the strength\n",
    "    #       of this scaling as a parameter.\n",
    "\n",
    "    # Create the output row.\n",
    "    flux_list = df[\"flux\"].reset_index(drop=True).transpose()\n",
    "    out_row = {\n",
    "        \"filename\"    : in_row[\"filename\"],\n",
    "        \"temperature\" : in_row[\"temperature\"]\n",
    "    }\n",
    "\n",
    "    # Place the ordered fluxes in.\n",
    "    for i, flux in flux_list.items():\n",
    "        out_row[\"flux %03d\" % i] = flux\n",
    "\n",
    "    return out_row\n",
    "\n",
    "# Get two quadratic fits from the data in a pandas dataframe, one for each wing.\n",
    "# NOTE. Currently does not return anything about the fit quality.\n",
    "def get_quadratic_fits(df):\n",
    "    # Array to contain the results of the polynomial fits.\n",
    "    fits  = []\n",
    "\n",
    "    # Get wing limits.\n",
    "    W_LIMS = get_wings(df)\n",
    "\n",
    "    for wi in range(2):\n",
    "        # Dictionary to contain the wavelength, flux, and flux error.\n",
    "        wings = {}\n",
    "        # Extract values\n",
    "        for col in COL_NAMES:\n",
    "            wings[col] = df[col][\n",
    "                (df[\"wavelength\"] >= W_LIMS[wi][0]) &\n",
    "                (df[\"wavelength\"] <= W_LIMS[wi][1])\n",
    "            ].values\n",
    "\n",
    "        # The errors are stddev and numpy takes in variance, so we square the\n",
    "        #     values in that array.\n",
    "        wings[\"flux_err\"] = np.square(wings[\"flux_err\"])\n",
    "\n",
    "        # Fit the arrays.\n",
    "        fits.append(np.poly1d(np.polynomial.polynomial.polyfit(\n",
    "            wings[\"wavelength\"],   # x.\n",
    "            wings[\"flux\"],         # y.\n",
    "            2,                     # degree.\n",
    "            w = wings[\"flux_err\"], # y_err.\n",
    "            rcond=None, full=False\n",
    "        )[::-1]))\n",
    "\n",
    "    return fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad492d-6ebb-4987-9a08-2bd8d1d05f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# First approach: do one quadratic fit on each wing, then run all 6 parameters\n",
    "#     through a linear regression model to predict the temperature.\n",
    "\n",
    "# --+ Fit nine random files and plot.\n",
    "fig, axes = plt.subplots(3, 3, sharey = True, sharex = True)\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "colors = [\"#BAD9E9\", \"#CE5146\"]\n",
    "CUT_TYPE = 1 # 0 is only fits, 1 is whole curve.\n",
    "\n",
    "# Pre-determined test set (very ugly distributions).\n",
    "test_set = [\n",
    "    \"1705080048011933_ha.txt\", \"1611160044011083_ha.txt\", \"1707120021012623_ha.txt\",\n",
    "    \"1706010031012623_ha.txt\", \"1705070106012833_ha.txt\", \"1706010031012623_ha.txt\",\n",
    "    \"1608130026013533_ha.txt\", \"1702180032013013_ha.txt\", \"1704110041011683_ha.txt\"\n",
    "]\n",
    "\n",
    "for pi in range(9):\n",
    "    # Extract a random filename from the csv.\n",
    "    TESTFILE = data_astn[\"filename\"].sample(n=1).values[0]\n",
    "    # TESTFILE = test_set[pi]\n",
    "\n",
    "    # Create a dataframe from the txt file.\n",
    "    df = pd.read_csv(SPECTRA_PATH + TESTFILE, sep=\"\\s+\", header=None, names=COL_NAMES)\n",
    "\n",
    "    # Perform fits.\n",
    "    fits = get_quadratic_fits(df)\n",
    "\n",
    "    # Remove all data from df outside of the relevant region.\n",
    "    W_LIMS = get_wings(df)\n",
    "\n",
    "    if CUT_TYPE == 0:\n",
    "        df.drop(df[(\n",
    "            ((W_LIMS[0][0] > df[\"wavelength\"]) | (df[\"wavelength\"] > W_LIMS[0][1])) &\n",
    "            ((W_LIMS[1][0] > df[\"wavelength\"]) | (df[\"wavelength\"] > W_LIMS[1][1]))\n",
    "        )].index, inplace=True)\n",
    "    if CUT_TYPE == 1:\n",
    "        df.drop(df[(\n",
    "            (W_LIMS[0][0]-5 > df[\"wavelength\"]) | (df[\"wavelength\"] > W_LIMS[1][1]+5)\n",
    "        )].index, inplace=True)\n",
    "\n",
    "    # Plot df.\n",
    "    axes[int(pi/3)][pi%3].errorbar(\n",
    "        df[\"wavelength\"], df[\"flux\"], yerr=df[\"flux_err\"],\n",
    "        fmt = 'o', markersize=0.4, capsize=0.2, color=colors[0]\n",
    "    )\n",
    "\n",
    "    # Get two linspaces to plot the fit.\n",
    "    for wi in range(2):\n",
    "        x_vals = np.linspace(W_LIMS[wi][0], W_LIMS[wi][1], 100)\n",
    "        y_vals = fits[wi](x_vals)\n",
    "        axes[int(pi/3)][pi%3].plot(x_vals, y_vals, color=colors[1])\n",
    "\n",
    "    # Print title.\n",
    "    axes[int(pi/3)][pi%3].set_title(TESTFILE)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"NAME.png\")\n",
    "\n",
    "print(\"Quadratic examples:\")\n",
    "plt.show()\n",
    "\n",
    "# --+ Get and store the fits and the target temperature for all files.\n",
    "# Create the output dataframe.\n",
    "columns = [\"filename\", \"w1_x2\", \"w1_x1\", \"w1_c\", \"w2_x2\", \"w2_x1\", \"w2_c\", \"temperature\"]\n",
    "out_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Iterate through all files.\n",
    "for in_row in data_astn.iterrows():\n",
    "    # Get the pandas dataframe.\n",
    "    in_df = pd.read_csv(\n",
    "        SPECTRA_PATH + in_row[1][\"filename\"], sep=\"\\s+\", header=None, names=COL_NAMES\n",
    "    )\n",
    "\n",
    "    # Extract the fits.\n",
    "    fits = get_quadratic_fits(in_df)\n",
    "\n",
    "    # Form the row.\n",
    "    out_row = {\n",
    "        \"filename\"    : in_row[1][\"filename\"],\n",
    "        \"w1_x2\"       : fits[0][0],\n",
    "        \"w1_x1\"       : fits[0][1],\n",
    "        \"w1_c\"        : fits[0][2],\n",
    "        \"w2_x2\"       : fits[1][0],\n",
    "        \"w2_x1\"       : fits[1][1],\n",
    "        \"w2_c\"        : fits[1][2],\n",
    "        \"temperature\" : in_row[1][\"temperature\"]\n",
    "    }\n",
    "\n",
    "    # Append row to output dataframe.\n",
    "    out_df.loc[in_row[0]] = out_row\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Pairplot to look at correlations. Very high correlation between each quadratic\n",
    "#     fit parameter. We'd expect one parameter to be superfluous (due to formula\n",
    "#     ax^2 + bx + c = 0), but not all of them. Weird.\n",
    "sns.pairplot(out_df)\n",
    "\n",
    "print(\"\\nPairplot:\")\n",
    "plt.show()\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Prepare X_train, X_test, y_train, y_test.\n",
    "X = out_df[[\"w1_x2\", \"w1_x1\", \"w1_c\", \"w2_x2\", \"w2_x1\", \"w2_c\"]]\n",
    "y = out_df[\"temperature\"]\n",
    "\n",
    "# Scale X and y. This is not necessary for linear regression, but might as well\n",
    "#     do it now instead of forgetting to do it if we try more complex models in\n",
    "#     the future. Also this scaling method is pretty bad, should use MinMax.\n",
    "X_scalers = [x.max() if x.max() > abs(x.min()) else abs(x.min()) for _, x in X.items()]\n",
    "y_scaler  = y.max() # y is strictly positive.\n",
    "\n",
    "X_scaled = X / X_scalers\n",
    "y_scaled = y / y_scaler\n",
    "\n",
    "# Split of 80:20.\n",
    "cutoff = int(.80 * X_scaled.shape[0])\n",
    "\n",
    "X_train = X_scaled[:cutoff]\n",
    "X_test  = X_scaled[cutoff:]\n",
    "y_train = y_scaled[:cutoff]\n",
    "y_test  = y_scaled[cutoff:]\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Train lr models with different number of polynomial features.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "r2_scores = {}\n",
    "y_preds   = {}\n",
    "\n",
    "for d in range(1, 11):\n",
    "    # Get polynomial features.\n",
    "    p2r = PolynomialFeatures(degree = d)\n",
    "    X_train_poly = p2r.fit_transform(X_train)\n",
    "    X_test_poly  = p2r.transform(X_test)\n",
    "\n",
    "    # Fit and predict w/ linear regression.\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_poly, y_train)\n",
    "\n",
    "    y_preds[d]   = lr.predict(X_test_poly)\n",
    "    r2_scores[d] = r2_score(y_preds[d], y_test)\n",
    "\n",
    "# Negative R2 scores make sense considering the high degree of the polynomial\n",
    "#     features. Suggests that a dense network might give good results, but we'd\n",
    "#     need more data.\n",
    "print(\"\\nR^2 scores:\")\n",
    "for d in range(1, 11):\n",
    "    print(\"  * polyfit (%d): %8.5f\" % (d, r2_scores[d]))\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "palette = [\"#96D5A4\", \"#FA9A58\", \"#ED6345\", \"#CF384D\"]\n",
    "\n",
    "# Make lineplots.\n",
    "sns.lineplot(y_scaler * y_test.values, color = palette[0], label = \"Real values\")\n",
    "for d in range(1, 4):\n",
    "    sns.lineplot(y_scaler * y_preds[d], color = palette[d], label = \"Polyfit (%d)\" % d, dashes=(2,2))\n",
    "\n",
    "plt.ylim(5000, 7500)\n",
    "\n",
    "# Set labels and such.\n",
    "plt.ylabel(\"T_eff\")\n",
    "plt.legend(loc = \"upper right\")\n",
    "# plt.savefig(\"NAME.png\")\n",
    "\n",
    "print(\"\\nPolynomial fits results:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b370dc-d07f-4393-b21e-adcbea457ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# Second approach: Perform a PCA decomposition on all data points in the wings.\n",
    "#     Then, run all PCA components through a linear regression model to predict\n",
    "#     the temperature.\n",
    "\n",
    "# Run a linear regression model on a PCA decomposition of the data points on the\n",
    "#     2 wings of a set of flux spectra files. The process uses three hyperpar-\n",
    "#     ameters:\n",
    "#       * WING_P1     : Wing maximum distance from distribution minimum.\n",
    "#       * WING_P2     : Wing minimum distance from distribution minimum.\n",
    "#       * N_PCA_COMPS : Number of PCA components to extract.\n",
    "# Returns a tuple with mean absolute error, mean squared error, and R2 score.\n",
    "def linreg_Teff(WING_P1=10, WING_P2=4, N_PCA_COMPS=20, plot=False, debug=False):\n",
    "    # --+ Create the output dataframe.\n",
    "    column_list = list(get_row(data_astn.loc[0], WING_P1, WING_P2).keys())\n",
    "    out_df = pd.DataFrame(columns=column_list)\n",
    "\n",
    "    for in_row in data_astn.iterrows():\n",
    "        out_df.loc[in_row[0]] = get_row(in_row[1], WING_P1, WING_P2)\n",
    "\n",
    "    # Remove columns with NaN values.\n",
    "    out_df = out_df.dropna(axis = 1)\n",
    "    \n",
    "    # --+ Prepare X_train, X_test, y_train, y_test\n",
    "    # Get X and y.\n",
    "    X = out_df.drop([\"filename\", \"temperature\"], axis=1)\n",
    "    y = out_df[\"temperature\"]\n",
    "\n",
    "    # Scale.\n",
    "    (X_scaled, X_min, X_max) = scale(X)\n",
    "    (y_scaled, y_min, y_max) = scale(y)\n",
    "\n",
    "    # Split 80:20.\n",
    "    cutoff = int(.80 * X_scaled.shape[0])\n",
    "\n",
    "    X_train = X_scaled[:cutoff]\n",
    "    X_test  = X_scaled[cutoff:]\n",
    "    y_train = y_scaled[:cutoff]\n",
    "    y_test  = y_scaled[cutoff:]\n",
    "\n",
    "    # --+ Perform PCA.\n",
    "    pca = PCA(n_components = N_PCA_COMPS)\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test  = pca.transform(X_test)\n",
    "\n",
    "    if (debug):\n",
    "        print(\"PCA explained variance ratios:\")\n",
    "        ratios = pca.explained_variance_ratio_\n",
    "        for i in range(len(ratios)):\n",
    "            print(\"  * PCA param %2d: %6.4f\" % (i, ratios[i]))\n",
    "\n",
    "    # --+ Train lr model.\n",
    "    # Fit and predict w/ linear regression.\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    # --+ Plot.\n",
    "    if plot:\n",
    "        palette = [\"#96D5A4\", \"#FA9A58\"]\n",
    "\n",
    "        # Make lineplots.\n",
    "        sns.lineplot(\n",
    "            descale(y_test.values, y_min, y_max),\n",
    "            color = palette[0], label = \"Real values\"\n",
    "        )\n",
    "        sns.lineplot(\n",
    "            descale(y_pred, y_min, y_max),\n",
    "            color = palette[1], label = \"Linear regression\", dashes = (2,2)\n",
    "        )\n",
    "\n",
    "        # Set labels and such.\n",
    "        plt.ylabel(\"T_eff\")\n",
    "        plt.legend(loc = \"upper right\")\n",
    "        plt.ylim(5000, 7500)\n",
    "\n",
    "        # plt.savefig(\"NAME.png\")\n",
    "        print(\"\\nLinear regression result:\")\n",
    "        plt.show()\n",
    "\n",
    "    return (\n",
    "        mean_absolute_error(y_test, y_pred),\n",
    "        mean_squared_error( y_test, y_pred),\n",
    "        r2_score(           y_test, y_pred)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6843195-ffcc-46b5-885c-7d826551ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(columns=(\"wing r_max\", \"wing r_min\", \"n pca components\", \"mae\", \"mse\", \"R2 score\"))\n",
    "\n",
    "for WING_P1 in np.linspace(2, 12, 21):\n",
    "    for WING_P2 in np.linspace(0, 10, 21):\n",
    "        if WING_P1 < WING_P2:\n",
    "            continue\n",
    "\n",
    "        for N_PCA_COMPS in np.arange(2, 12, 2):\n",
    "            try:\n",
    "                res = linreg_Teff(WING_P1, WING_P2, N_PCA_COMPS)\n",
    "            except ValueError: # On extreme cases, we won't get enough data points for doing PCA.\n",
    "                continue\n",
    "\n",
    "            res_row = pd.DataFrame({\n",
    "                \"wing r_max\"       : [WING_P1],\n",
    "                \"wing r_min\"       : [WING_P2],\n",
    "                \"n pca components\" : [N_PCA_COMPS],\n",
    "                \"mae\"              : [res[0]],\n",
    "                \"mse\"              : [res[1]],\n",
    "                \"R2 score\"         : [res[2]]\n",
    "            })\n",
    "\n",
    "            # Append row to output dataframe.\n",
    "            res_df = pd.concat([res_df, res_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e9ea6-41e1-4129-b20c-13cd01e3b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check best performing PCA numbers.\n",
    "res_df_npc = res_df.groupby(\"n pca components\").mean().reset_index()\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, sharey = False, sharex = True)\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "\n",
    "metrics = (\"mae\", \"mse\", \"R2 score\")\n",
    "\n",
    "for pi in range(3):\n",
    "    axes[pi].plot(res_df_npc[\"n pca components\"], res_df_npc[metrics[pi]])\n",
    "    axes[pi].set_title(metrics[pi])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf136f8-2e8b-42b3-843e-99ca2554ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = {\n",
    "    \"mae\"      : pd.DataFrame(columns=(\"wing r_max\", \"wing r_min\", \"n pca components\", \"mae\", \"mse\", \"R2 score\")),\n",
    "    \"mse\"      : pd.DataFrame(columns=(\"wing r_max\", \"wing r_min\", \"n pca components\", \"mae\", \"mse\", \"R2 score\")),\n",
    "    \"R2 score\" : pd.DataFrame(columns=(\"wing r_max\", \"wing r_min\", \"n pca components\", \"mae\", \"mse\", \"R2 score\"))\n",
    "}\n",
    "\n",
    "for WING_P1 in np.linspace(2, 12, 21):\n",
    "    for WING_P2 in np.linspace(0, 10, 21):\n",
    "        df = res_df.loc[(res_df[\"wing r_max\"] == WING_P1) & (res_df[\"wing r_min\"] == WING_P2)]\n",
    "\n",
    "        for metric in metrics:\n",
    "            if df[metric].empty: continue\n",
    "            idx = df[metric].idxmax() if metric == \"R2 score\" else df[metric].idxmin()\n",
    "            row = df.loc[[idx]]\n",
    "            best_results[metric] = pd.concat([best_results[metric], row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a321c7-3e13-4276-84f8-e0937193d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "    for metric in metrics:\n",
    "        # Make plot.\n",
    "        heatmap_data = best_results[metric].pivot(index=\"wing r_max\", columns=\"wing r_min\", values=metric)\n",
    "        sns.heatmap(heatmap_data, linewidth=.5, annot=True, annot_kws={\"size\": 9})\n",
    "\n",
    "        # Show.\n",
    "        plt.title(metric)\n",
    "        plt.savefig(\"heatmap_%s.png\" % metric)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14aed13-0522-44e3-9c1f-bc57fb01f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. For the best model, see how robust it is if we change the train set. Then, test different train set sizes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
